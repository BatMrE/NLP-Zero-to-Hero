{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":" # NLP Zero to Hero\n \n##### In this notebook I have tried to cover almost all the domains and model types of NLP.\n##### I have attached some notebooks, code references and papers for furthur understanding\n##### Feel free to copy this code and markdown into your Kaggle notebook\n\n","metadata":{}},{"cell_type":"markdown","source":" ## 🌟 Introduction 🌟\n\nNatural Language Processing is a sub-field of artificial intelligence that focuses on the interaction between computers and humans through natural language. The ultimate objective of NLP is to enable computers to understand, interpret, and generate human languages in a way that is both meaningful and useful.\n\n### 🚀 Why is NLP Important?\n\nNLP is important because it helps resolve ambiguity in language and adds useful numeric representation to the data for many downstream applications, such as text analytics or speech recognition. Here are some reasons why NLP is important:\n\n1. 📊 **Volume of Text Data**: With the explosion of digital communication, the amount of text data generated daily is vast. NLP helps in extracting useful information from this vast amount of unstructured data.\n2. 🗣️ **Human-Computer Interaction**: NLP provides more natural interactions between humans and computers, making technologies like virtual assistants and chatbots more effective.\n3. ⚙️ **Automation of Routine Tasks**: NLP can automate and align routine tasks such as summarizing documents, filtering spam emails, and translating languages.\n\n### Applications of NLP\n\nNLP has a wide range of applications across various domains:\n\n- 📥 **Text Classification**: Categorizing text into predefined categories. For example, filtering spam emails or classifying customer reviews.\n- 😃 **Sentiment Analysis**: Determining the sentiment expressed in a piece of text, such as identifying positive or negative reviews.\n- 🌐 **Machine Translation**: Translating text from one language to another, like Google Translate.\n- 🔍 **Named Entity Recognition (NER)**: Identifying entities such as names, dates, and places within a text.\n- 🎤 **Speech Recognition**: Converting spoken language into text, as used in virtual assistants like Siri and Alexa.\n- 🤖 **Chatbots**: Enabling conversational agents to understand and respond to human queries in real-time.\n- ✍️ **Text Summarization**: Creating a summary of a longer piece of text.\n","metadata":{}},{"cell_type":"markdown","source":"### 🧠 Some Basic NLP Concepts and Terminology\n\nBefore looking into NLP tasks, it's essential to understand some basic concepts and terminology:\n\n- ✂️ **Tokenization**: The process of splitting text into individual words or phrases, known as tokens.\n- 🛑 **Stopwords**: Common words like \"the\", \"is\", \"in\", which are often removed from text before processing because they add little value to the analysis.\n- 🌱 **Stemming and Lemmatization**: Techniques to reduce words to their base or root form. Stemming is a crude heuristic process that chops off the ends of words, while lemmatization uses a dictionary to find the root form.\n- 🔢 **Vectorization**: Converting text into numerical format. Common methods include Bag of Words (BoW) and Term Frequency-Inverse Document Frequency (TF-IDF).\n- 💬 **Word Embeddings**: Dense vector representations of words, capturing their meanings, semantic relationships, and context. Examples include Word2Vec, GloVe, and FastText.\n- 🔄 **Sequence Models**: Models like Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTM), and Gated Recurrent Units (GRUs) that are capable of processing sequences of data.\n- ⚡ **Transformers**: A type of model architecture that has revolutionized NLP, particularly through models like BERT, GPT, and T5. Transformers handle sequences in parallel and have shown significant improvements in various NLP tasks.","metadata":{}},{"cell_type":"markdown","source":"### Structure of This Notebook\n\nI have identified the following topics from basic NLP tasks to more advanced techniques:\n\n1. **Text Preprocessing**\n   - Tokenization\n   - Stopword removal\n   - Stemming and Lemmatization\n   - Vectorization\n\n2. **Basic NLP Tasks**\n   - Sentiment Analysis\n   - Named Entity Recognition (NER)\n   - Part-of-Speech Tagging\n   - Text Classification\n   \n3. **Word Embeddings**\n   - Introduction to Word Embeddings\n   - Word2Vec\n   - GloVe\n   - FastText\n   \n4. **Sequence Models**\n   - Recurrent Neural Networks (RNN)\n   - Long Short-Term Memory (LSTM) Networks\n   - Gated Recurrent Units (GRU)\n\n5. **Attention Mechanisms and Transformers**\n   - Attention Mechanisms\n   - Transformer Architecture\n   - Implementing Transformers\n   \n6. **BERT and Transformer-based Models**\n   - BERT (Bidirectional Encoder Representations from Transformers\n   - Variants of BERT\n   - GPT (Generative Pre-trained Transformer)\n   - T5 (Text-To-Text Transfer Transformer)\n   - Other Transformer-based Models\n   \n7. **Advanced Embeddings and Contextualized Word Representations**\n   - ELMo (Embeddings from Language Models)\n   - ULMFiT (Universal Language Model Fine-tuning)\n   - Contextualized Embeddings in Practice\n   \n8. **Advanced Sequence Models**\n   - Bidirectional RNNs (BiRNN)\n   - Sequence-to-Sequence (Seq2Seq) Models\n   - Transformer-based Seq2Seq Models\n   \n9. **Generative AI**\n   - Autoregressive Models\n   - Generative Adversarial Networks\n   - Variational Autoencoders\n   \n\nLet's begin","metadata":{}},{"cell_type":"markdown","source":"# 🌟 Part 1 : Text Preprocessing 🌟","metadata":{}},{"cell_type":"markdown","source":"### 📝 Importing libraries","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nimport spacy","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:48:37.302229Z","iopub.execute_input":"2024-07-01T22:48:37.302607Z","iopub.status.idle":"2024-07-01T22:48:37.309328Z","shell.execute_reply.started":"2024-07-01T22:48:37.302581Z","shell.execute_reply":"2024-07-01T22:48:37.308067Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"#### 🚀 Let's download NLTK and Spacy data we need (just once)","metadata":{}},{"cell_type":"code","source":"!python -m spacy download en_core_web_md","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:48:37.310990Z","iopub.execute_input":"2024-07-01T22:48:37.311365Z","iopub.status.idle":"2024-07-01T22:48:53.790637Z","shell.execute_reply.started":"2024-07-01T22:48:37.311335Z","shell.execute_reply":"2024-07-01T22:48:53.789452Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting en-core-web-md==3.7.1\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.7.1/en_core_web_md-3.7.1-py3-none-any.whl (42.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /opt/conda/lib/python3.10/site-packages (from en-core-web-md==3.7.1) (3.7.4)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.2.3)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.10)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.3.4)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.9.0)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (6.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.66.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.31.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.5.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.1.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (69.0.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.3.0)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.26.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.1.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2024.2.2)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.4)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.1.7)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.1.3)\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_md')\n","output_type":"stream"}]},{"cell_type":"code","source":"nltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('wordnet')\nnlp = spacy.load('en_core_web_sm')\n# nltk.download('omw-1.4')","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:48:53.792913Z","iopub.execute_input":"2024-07-01T22:48:53.793317Z","iopub.status.idle":"2024-07-01T22:48:54.681090Z","shell.execute_reply.started":"2024-07-01T22:48:53.793282Z","shell.execute_reply":"2024-07-01T22:48:54.679841Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"text = \"\"\"\nThe Kaggle community has a lot of diversity, with members from over 100 countries and skill levels ranging from those learning Python through to the researchers who created deep neural networks. We have had competition winners with backgrounds ranging from computer science to English literature. However, all our users share a common thread: you love working with data.\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:48:54.682462Z","iopub.execute_input":"2024-07-01T22:48:54.682786Z","iopub.status.idle":"2024-07-01T22:48:54.692466Z","shell.execute_reply.started":"2024-07-01T22:48:54.682761Z","shell.execute_reply":"2024-07-01T22:48:54.691332Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"### 🪄 Step 1: Tokenization - Breaking text into words (tokens) 🌟","metadata":{}},{"cell_type":"code","source":"tokens = word_tokenize(text)\nprint(\"🔹 Tokens:\", tokens)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:48:54.694757Z","iopub.execute_input":"2024-07-01T22:48:54.695126Z","iopub.status.idle":"2024-07-01T22:48:54.705594Z","shell.execute_reply.started":"2024-07-01T22:48:54.695097Z","shell.execute_reply":"2024-07-01T22:48:54.704383Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"🔹 Tokens: ['FeatureLens', 'generates', 'visuals', 'by', 'applying', 'text', 'mining', 'concepts', 'such', 'as', 'frequent', 'words', ',', 'expressions', ',', 'and', 'closed', 'itemsets', 'of', 'n-grams', 'to', 'guide', 'the', 'discovery', 'process', '.', 'These', 'concepts', 'are', 'combined', 'with', 'interactive', 'visualization', 'to', 'help', 'users', 'analyze', 'text', ',', 'create', 'insights']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 🛑 Step 2: Stopword removal - Get rid of those pesky common words 🛑","metadata":{}},{"cell_type":"code","source":"\nstop_words = set(stopwords.words('english'))\nfiltered_tokens = [word for word in tokens if word.lower() not in stop_words]\nprint(\"🔹 Tokens after stopword removal:\", filtered_tokens)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:48:54.706788Z","iopub.execute_input":"2024-07-01T22:48:54.707176Z","iopub.status.idle":"2024-07-01T22:48:54.718500Z","shell.execute_reply.started":"2024-07-01T22:48:54.707148Z","shell.execute_reply":"2024-07-01T22:48:54.717525Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"🔹 Tokens after stopword removal: ['FeatureLens', 'generates', 'visuals', 'applying', 'text', 'mining', 'concepts', 'frequent', 'words', ',', 'expressions', ',', 'closed', 'itemsets', 'n-grams', 'guide', 'discovery', 'process', '.', 'concepts', 'combined', 'interactive', 'visualization', 'help', 'users', 'analyze', 'text', ',', 'create', 'insights']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### ✂️ Step 3: Stemming - Chopping words to their roots using PorterStemmer! ✂️","metadata":{}},{"cell_type":"code","source":"stemmer = PorterStemmer()\nstemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\nprint(\"🔹 Stemmed tokens:\", stemmed_tokens)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:48:54.719887Z","iopub.execute_input":"2024-07-01T22:48:54.720812Z","iopub.status.idle":"2024-07-01T22:48:54.729576Z","shell.execute_reply.started":"2024-07-01T22:48:54.720775Z","shell.execute_reply":"2024-07-01T22:48:54.728396Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"🔹 Stemmed tokens: ['featurelen', 'gener', 'visual', 'appli', 'text', 'mine', 'concept', 'frequent', 'word', ',', 'express', ',', 'close', 'itemset', 'n-gram', 'guid', 'discoveri', 'process', '.', 'concept', 'combin', 'interact', 'visual', 'help', 'user', 'analyz', 'text', ',', 'creat', 'insight']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 🌱 Step 4: Lemmatization - Morphing words to their base form with WordNetLemmatizer! 🌱","metadata":{}},{"cell_type":"code","source":"def lemmatize_with_spacy(tokens):\n    doc = nlp(' '.join(tokens))\n    return [token.lemma_ for token in doc]\n\nlemmatized_tokens = lemmatize_with_spacy(filtered_tokens)\nprint(\"🔹 Lemmatized tokens:\", lemmatized_tokens)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:48:54.730936Z","iopub.execute_input":"2024-07-01T22:48:54.731347Z","iopub.status.idle":"2024-07-01T22:48:54.761524Z","shell.execute_reply.started":"2024-07-01T22:48:54.731318Z","shell.execute_reply":"2024-07-01T22:48:54.760484Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"🔹 Lemmatized tokens: ['FeatureLens', 'generate', 'visual', 'apply', 'text', 'mining', 'concept', 'frequent', 'word', ',', 'expression', ',', 'closed', 'itemset', 'n', '-', 'gram', 'guide', 'discovery', 'process', '.', 'concept', 'combine', 'interactive', 'visualization', 'help', 'user', 'analyze', 'text', ',', 'create', 'insight']\n","output_type":"stream"}]},{"cell_type":"code","source":"# lemmatizer = WordNetLemmatizer()\n# lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n# print(\"🔹 Lemmatized tokens:\", lemmatized_tokens)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:48:54.762909Z","iopub.execute_input":"2024-07-01T22:48:54.763310Z","iopub.status.idle":"2024-07-01T22:48:54.767374Z","shell.execute_reply.started":"2024-07-01T22:48:54.763280Z","shell.execute_reply":"2024-07-01T22:48:54.766381Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"### 💼 Step 5: Vectorization - Turn those words into numbers for our model! 📊","metadata":{}},{"cell_type":"markdown","source":"#### 🧮 Count Vectorizer - Counting word occurrences","metadata":{}},{"cell_type":"code","source":"count_vectorizer = CountVectorizer()\ncount_vectors = count_vectorizer.fit_transform([' '.join(lemmatized_tokens)])\nprint(\"🔹 Count Vectorizer feature names:\", count_vectorizer.get_feature_names_out())\nprint(\"🔹 Count Vectors:\\n\", count_vectors.toarray())","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:48:54.768778Z","iopub.execute_input":"2024-07-01T22:48:54.769180Z","iopub.status.idle":"2024-07-01T22:48:54.782506Z","shell.execute_reply.started":"2024-07-01T22:48:54.769146Z","shell.execute_reply":"2024-07-01T22:48:54.781427Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"🔹 Count Vectorizer feature names: ['analyze' 'apply' 'closed' 'combine' 'concept' 'create' 'discovery'\n 'expression' 'featurelens' 'frequent' 'generate' 'gram' 'guide' 'help'\n 'insight' 'interactive' 'itemset' 'mining' 'process' 'text' 'user'\n 'visual' 'visualization' 'word']\n🔹 Count Vectors:\n [[1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### 🔥 TF-IDF Vectorizer - Considering word frequency across documents","metadata":{}},{"cell_type":"code","source":"tfidf_vectorizer = TfidfVectorizer()\ntfidf_vectors = tfidf_vectorizer.fit_transform([' '.join(lemmatized_tokens)])\nprint(\"🔹 TF-IDF Vectorizer feature names:\", tfidf_vectorizer.get_feature_names_out())\nprint(\"🔹 TF-IDF Vectors:\\n\", tfidf_vectors.toarray())","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:48:54.786386Z","iopub.execute_input":"2024-07-01T22:48:54.786723Z","iopub.status.idle":"2024-07-01T22:48:54.801732Z","shell.execute_reply.started":"2024-07-01T22:48:54.786693Z","shell.execute_reply":"2024-07-01T22:48:54.800670Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"🔹 TF-IDF Vectorizer feature names: ['analyze' 'apply' 'closed' 'combine' 'concept' 'create' 'discovery'\n 'expression' 'featurelens' 'frequent' 'generate' 'gram' 'guide' 'help'\n 'insight' 'interactive' 'itemset' 'mining' 'process' 'text' 'user'\n 'visual' 'visualization' 'word']\n🔹 TF-IDF Vectors:\n [[0.18257419 0.18257419 0.18257419 0.18257419 0.36514837 0.18257419\n  0.18257419 0.18257419 0.18257419 0.18257419 0.18257419 0.18257419\n  0.18257419 0.18257419 0.18257419 0.18257419 0.18257419 0.18257419\n  0.18257419 0.36514837 0.18257419 0.18257419 0.18257419 0.18257419]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### 🎉 And that's it guys! Our text is now preprocessed and ready for some NLP magic! 🎉","metadata":{}},{"cell_type":"markdown","source":"# 🌟 Part 2 : Basic NLP Tasks 🌟","metadata":{}},{"cell_type":"markdown","source":"####  🎉 Now, let's dive into some basic NLP tasks! 🎉","metadata":{}},{"cell_type":"markdown","source":"### 📢 Task 1: Sentiment Analysis - Get those text vibes! 😃😢😡","metadata":{}},{"cell_type":"code","source":"# NLTK's VADER for sentiment analysis\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nsid = SentimentIntensityAnalyzer()\n\nsentiment_scores = sid.polarity_scores(text)\nprint(\"🔹 Sentiment Scores:\", sentiment_scores)\n\ndef get_sentiment_label(scores):\n    if scores['compound'] >= 0.05:\n        return 'positive'\n    elif scores['compound'] <= -0.05:\n        return 'negative'\n    else:\n        return 'neutral'\n    \nsentiment_label = get_sentiment_label(sentiment_scores)\nprint(f\"🔹 Sentiment Label: {sentiment_label}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:48:54.802985Z","iopub.execute_input":"2024-07-01T22:48:54.803288Z","iopub.status.idle":"2024-07-01T22:48:54.822938Z","shell.execute_reply.started":"2024-07-01T22:48:54.803263Z","shell.execute_reply":"2024-07-01T22:48:54.821904Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"🔹 Sentiment Scores: {'neg': 0.0, 'neu': 0.879, 'pos': 0.121, 'compound': 0.5859}\n🔹 Sentiment Label: positive\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 🎭 Task 2: Named Entity Recognition (NER) - Who's who and what's what? 🤔","metadata":{}},{"cell_type":"code","source":"doc = nlp(text)\n\nentities = [(entity.text, entity.label_) for entity in doc.ents]\nprint(\"🔹 Named Entities:\", entities)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:48:54.824396Z","iopub.execute_input":"2024-07-01T22:48:54.824718Z","iopub.status.idle":"2024-07-01T22:48:54.847506Z","shell.execute_reply.started":"2024-07-01T22:48:54.824685Z","shell.execute_reply":"2024-07-01T22:48:54.846400Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"🔹 Named Entities: [('FeatureLens', 'ORG')]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 🏷️ Task 3: Part-of-Speech Tagging - Tagging words like a pro! 🏷️","metadata":{}},{"cell_type":"code","source":"pos_tags = [(token.text, token.pos_) for token in doc]\nprint(\"🔹 Part-of-Speech Tags:\", pos_tags)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:48:54.848552Z","iopub.execute_input":"2024-07-01T22:48:54.848878Z","iopub.status.idle":"2024-07-01T22:48:54.854736Z","shell.execute_reply.started":"2024-07-01T22:48:54.848852Z","shell.execute_reply":"2024-07-01T22:48:54.853654Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"🔹 Part-of-Speech Tags: [('\\n', 'SPACE'), ('FeatureLens', 'PROPN'), ('generates', 'VERB'), ('visuals', 'NOUN'), ('by', 'ADP'), ('applying', 'VERB'), ('text', 'NOUN'), ('mining', 'NOUN'), ('concepts', 'NOUN'), ('such', 'ADJ'), ('as', 'ADP'), ('frequent', 'ADJ'), ('words', 'NOUN'), (',', 'PUNCT'), ('expressions', 'NOUN'), (',', 'PUNCT'), ('and', 'CCONJ'), ('closed', 'ADJ'), ('itemsets', 'NOUN'), ('of', 'ADP'), ('n', 'NOUN'), ('-', 'PUNCT'), ('grams', 'NOUN'), ('to', 'PART'), ('guide', 'VERB'), ('the', 'DET'), ('discovery', 'NOUN'), ('process', 'NOUN'), ('.', 'PUNCT'), ('These', 'DET'), ('concepts', 'NOUN'), ('are', 'AUX'), ('combined', 'VERB'), ('with', 'ADP'), ('interactive', 'ADJ'), ('visualization', 'NOUN'), ('to', 'PART'), ('help', 'VERB'), ('users', 'NOUN'), ('analyze', 'VERB'), ('text', 'NOUN'), (',', 'PUNCT'), ('create', 'VERB'), ('insights', 'NOUN'), ('\\n', 'SPACE')]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 📚 Task 4: Text Classification - Let's train a simple classifier! 📚","metadata":{}},{"cell_type":"code","source":"train_texts = [\n    \"I love sunny days\",\n    \"I hate rainy days\",\n    \"Sunshine makes me happy\",\n    \"Rainy days make me sad\"\n]\ntrain_labels = ['positive', 'negative', 'positive', 'negative']","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:48:54.855846Z","iopub.execute_input":"2024-07-01T22:48:54.856237Z","iopub.status.idle":"2024-07-01T22:48:54.864714Z","shell.execute_reply.started":"2024-07-01T22:48:54.856209Z","shell.execute_reply":"2024-07-01T22:48:54.863747Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":"#### 🧑‍🏫 Step 1: Vectorize the training texts","metadata":{}},{"cell_type":"code","source":"vectorizer = CountVectorizer()\nX_train = vectorizer.fit_transform(train_texts)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:48:54.866009Z","iopub.execute_input":"2024-07-01T22:48:54.866340Z","iopub.status.idle":"2024-07-01T22:48:54.876557Z","shell.execute_reply.started":"2024-07-01T22:48:54.866313Z","shell.execute_reply":"2024-07-01T22:48:54.875528Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"#### 🧠 Step 2: Train a simple classifier (Naive Bayes)","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\n\nclassifier = MultinomialNB()\nclassifier.fit(X_train, train_labels)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:48:54.878050Z","iopub.execute_input":"2024-07-01T22:48:54.878432Z","iopub.status.idle":"2024-07-01T22:48:54.892121Z","shell.execute_reply.started":"2024-07-01T22:48:54.878402Z","shell.execute_reply":"2024-07-01T22:48:54.891123Z"},"trusted":true},"execution_count":64,"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"MultinomialNB()","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### 🎓 Step 3: Predict sentiment of a new text","metadata":{}},{"cell_type":"code","source":"new_text = \"I feel happy when it is sunny\"\nX_new = vectorizer.transform([new_text])\npredicted_label = classifier.predict(X_new)[0]\nprint(f\"🔹 New Text: {new_text}\")\nprint(f\"🔹 Predicted Sentiment: {predicted_label}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:48:54.893274Z","iopub.execute_input":"2024-07-01T22:48:54.893587Z","iopub.status.idle":"2024-07-01T22:48:54.901886Z","shell.execute_reply.started":"2024-07-01T22:48:54.893556Z","shell.execute_reply":"2024-07-01T22:48:54.900935Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"🔹 New Text: I feel happy when it is sunny\n🔹 Predicted Sentiment: positive\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### 🎉 And that's a wrap on our basic NLP tasks! You're now an NLP hero! 🎉","metadata":{}},{"cell_type":"markdown","source":"# 🌟 Part 3 : Word Embeddings 🌟","metadata":{}},{"cell_type":"markdown","source":"### 🧠 Introduction to Word Embeddings","metadata":{}},{"cell_type":"markdown","source":"#####  🗣️ Word embeddings give us a way to use an efficient, dense representation in which similar words have a similar encoding. An embedding is a dense vector of floating point values\n [TensorFlow/Word embeddings](https://www.tensorflow.org/text/guide/word_embeddings#word_embeddings_2)\n\n##### We use Word Embeddings for:\n* Contextual Understanding\n* Efficient Representation\n* Improved Performance\n","metadata":{}},{"cell_type":"markdown","source":"### 🏋️ Word2Vec","metadata":{}},{"cell_type":"markdown","source":"##### Word2Vec developed by Google has two flavors: Continuous Bag of Words (CBOW) and Skip-gram. Let’s look into some code! 🛠️\n","metadata":{}},{"cell_type":"code","source":"import gensim\nfrom gensim.models import Word2Vec\n\nsentences = [\n    \"I love sunny days\",\n    \"I hate rainy days\",\n    \"Sunshine makes me happy\",\n    \"Rainy days make me sad\"\n]","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:48:54.903362Z","iopub.execute_input":"2024-07-01T22:48:54.903812Z","iopub.status.idle":"2024-07-01T22:48:54.912579Z","shell.execute_reply.started":"2024-07-01T22:48:54.903775Z","shell.execute_reply":"2024-07-01T22:48:54.911496Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"##### 🪄 Step 1: Tokenization (we did this before, but let's do it again for completeness)","metadata":{}},{"cell_type":"code","source":"tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]\nprint(\"🔹 Tokenized Sentences:\", tokenized_sentences)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:48:54.913905Z","iopub.execute_input":"2024-07-01T22:48:54.914534Z","iopub.status.idle":"2024-07-01T22:48:54.928223Z","shell.execute_reply.started":"2024-07-01T22:48:54.914506Z","shell.execute_reply":"2024-07-01T22:48:54.927019Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"🔹 Tokenized Sentences: [['i', 'love', 'sunny', 'days'], ['i', 'hate', 'rainy', 'days'], ['sunshine', 'makes', 'me', 'happy'], ['rainy', 'days', 'make', 'me', 'sad']]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"##### 🧠 Step 2: Train the Word2Vec model","metadata":{}},{"cell_type":"code","source":"word2vec_model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, workers=4)\nprint(\"🔹 Word2Vec Model Trained!\")","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:48:54.929673Z","iopub.execute_input":"2024-07-01T22:48:54.930031Z","iopub.status.idle":"2024-07-01T22:48:54.951683Z","shell.execute_reply.started":"2024-07-01T22:48:54.929997Z","shell.execute_reply":"2024-07-01T22:48:54.950704Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"🔹 Word2Vec Model Trained!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"##### 🔍 Step 3: Explore Word2Vec embeddings","metadata":{}},{"cell_type":"code","source":"word = \"sunny\"\nif word in word2vec_model.wv:\n    print(f\"🔹 Vector for '{word}':\", word2vec_model.wv[word])\nelse:\n    print(f\"🔹 Word '{word}' not in vocabulary\")","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:48:54.953064Z","iopub.execute_input":"2024-07-01T22:48:54.953374Z","iopub.status.idle":"2024-07-01T22:48:54.960858Z","shell.execute_reply.started":"2024-07-01T22:48:54.953347Z","shell.execute_reply":"2024-07-01T22:48:54.959757Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"🔹 Vector for 'sunny': [ 7.0887972e-03 -1.5679300e-03  7.9474989e-03 -9.4886590e-03\n -8.0294991e-03 -6.6403709e-03 -4.0034545e-03  4.9892161e-03\n -3.8135587e-03 -8.3199050e-03  8.4117772e-03 -3.7470020e-03\n  8.6086961e-03 -4.8957514e-03  3.9185942e-03  4.9220170e-03\n  2.3926091e-03 -2.8188038e-03  2.8491246e-03 -8.2562361e-03\n -2.7655398e-03 -2.5911583e-03  7.2490061e-03 -3.4634031e-03\n -6.5997029e-03  4.3404270e-03 -4.7448516e-04 -3.5975564e-03\n  6.8824720e-03  3.8723124e-03 -3.9002013e-03  7.7188847e-04\n  9.1435025e-03  7.7546560e-03  6.3618720e-03  4.6673026e-03\n  2.3844899e-03 -1.8416261e-03 -6.3712932e-03 -3.0181051e-04\n -1.5653884e-03 -5.7228567e-04 -6.2628710e-03  7.4340473e-03\n -6.5914928e-03 -7.2392775e-03 -2.7571463e-03 -1.5154004e-03\n -7.6357173e-03  6.9824100e-04 -5.3261113e-03 -1.2755442e-03\n -7.3651113e-03  1.9605684e-03  3.2731986e-03 -2.3138524e-05\n -5.4483581e-03 -1.7260861e-03  7.0849168e-03  3.7362587e-03\n -8.8810492e-03 -3.4135508e-03  2.3541022e-03  2.1380198e-03\n -9.4640078e-03  4.5711659e-03 -8.6569972e-03 -7.3870681e-03\n  3.4831120e-03 -3.4709584e-03  3.5644709e-03  8.8940905e-03\n -3.5743224e-03  9.3204249e-03  1.7110384e-03  9.8477742e-03\n  5.7050432e-03 -9.1494834e-03 -3.3277308e-03  6.5301750e-03\n  5.6027793e-03  8.7055154e-03  6.9261026e-03  8.0388878e-03\n -9.8230084e-03  4.2988253e-03 -5.0300765e-03  3.5123860e-03\n  6.0566878e-03  4.3921317e-03  7.5123594e-03  1.4977157e-03\n -1.2649416e-03  5.7684006e-03 -5.6395675e-03  3.8591625e-05\n  9.4565870e-03 -5.4812501e-03  3.8142789e-03 -8.1130210e-03]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"##### 👯‍♂️ Find similar words","metadata":{}},{"cell_type":"code","source":"similar_words = word2vec_model.wv.most_similar(word, topn=5)\nprint(f\"🔹 Words similar to '{word}':\", similar_words)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:48:54.962399Z","iopub.execute_input":"2024-07-01T22:48:54.962792Z","iopub.status.idle":"2024-07-01T22:48:54.972402Z","shell.execute_reply.started":"2024-07-01T22:48:54.962757Z","shell.execute_reply":"2024-07-01T22:48:54.971282Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"🔹 Words similar to 'sunny': [('love', 0.10941850394010544), ('makes', 0.10889014601707458), ('days', 0.06285077333450317), ('happy', 0.05048205703496933), ('sunshine', 0.026806795969605446)]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 🧬 GloVe (Global Vectors for Word Representation)","metadata":{}},{"cell_type":"markdown","source":"##### GloVe captures global statistical information by training on the non-zero entries of a word co-occurrence matrix. Let’s see it in action! 💡","metadata":{}},{"cell_type":"markdown","source":"##### 📢 If you are testing this notebook, ,ake sure to download and test the larger spaCy model for better results:\n##### python -m spacy download en_core_web_md","metadata":{}},{"cell_type":"code","source":"nlp_glove = spacy.load('en_core_web_md')","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:48:54.973701Z","iopub.execute_input":"2024-07-01T22:48:54.974061Z","iopub.status.idle":"2024-07-01T22:48:56.980607Z","shell.execute_reply.started":"2024-07-01T22:48:54.974026Z","shell.execute_reply":"2024-07-01T22:48:56.979503Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"##### 🔍 Explore GloVe embeddings","metadata":{}},{"cell_type":"code","source":"doc = nlp_glove(\"I love sunny days\")\nfor token in doc:\n    print(f\"🔹 Token: {token.text}, Vector: {token.vector[:5]}...\")  # Show first 5 dimensions for brevity","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:48:56.981921Z","iopub.execute_input":"2024-07-01T22:48:56.982247Z","iopub.status.idle":"2024-07-01T22:48:56.999142Z","shell.execute_reply.started":"2024-07-01T22:48:56.982221Z","shell.execute_reply":"2024-07-01T22:48:56.998087Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"🔹 Token: I, Vector: [ -1.8607    0.15804  -4.1425   -8.6359  -16.955  ]...\n🔹 Token: love, Vector: [ 2.0565  -3.2259  -5.7364  -6.146    0.15748]...\n🔹 Token: sunny, Vector: [-0.14498  0.65651 -2.8764   0.40125 -1.0028 ]...\n🔹 Token: days, Vector: [-3.0808  4.6691  1.1    -1.3048  4.1861]...\n","output_type":"stream"}]},{"cell_type":"markdown","source":"##### 👯‍♂️ Find similar words using spaCy's GloVe embeddings","metadata":{}},{"cell_type":"code","source":"def find_similar_words_spacy(word):\n    token = nlp_glove.vocab[word]\n    queries = [w for w in token.vocab if w.is_lower == token.is_lower and w.prob >= -15]\n    by_similarity = sorted(queries, key=lambda w: token.similarity(w), reverse=True)\n    return [w.text for w in by_similarity[:5]]\n\nword = \"sunny\"\nsimilar_words_glove = find_similar_words_spacy(word)\nprint(f\"🔹 Words similar to '{word}' using GloVe:\", similar_words_glove)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:48:57.000376Z","iopub.execute_input":"2024-07-01T22:48:57.000693Z","iopub.status.idle":"2024-07-01T22:48:57.008984Z","shell.execute_reply.started":"2024-07-01T22:48:57.000667Z","shell.execute_reply":"2024-07-01T22:48:57.007754Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"🔹 Words similar to 'sunny' using GloVe: []\n","output_type":"stream"}]},{"cell_type":"markdown","source":"##### 🎉 And that's a wrap on Word Embeddings! You're now a Word2Vec and GloVe pro! 🎉","metadata":{}},{"cell_type":"markdown","source":"### ⚡ FastText","metadata":{}},{"cell_type":"markdown","source":"##### FastText extends the Word2Vec by making embeddings for character n-grams which allows it to handle out-of-vocabulary words better. Let's see how FastText can be implemented! 💥","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import brown\nnltk.download('brown')\n\nsentences = brown.sents()\nfrom gensim.models import FastText\n\nfasttext_model = FastText(sentences, vector_size=100, window=5, min_count=5, workers=4)\nfasttext_model.save(\"fasttext.model\")\nfasttext_model = FastText.load(\"fasttext.model\")\n\nprint(\"🔹 Vector for 'king' : \", fasttext_model.wv['king'])\nprint(\"🔹 Most similar to 'queen' : \", fasttext_model.wv.most_similar('queen'))","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:48:57.010295Z","iopub.execute_input":"2024-07-01T22:48:57.010611Z","iopub.status.idle":"2024-07-01T22:49:26.527348Z","shell.execute_reply.started":"2024-07-01T22:48:57.010585Z","shell.execute_reply":"2024-07-01T22:49:26.526242Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package brown to /usr/share/nltk_data...\n[nltk_data]   Package brown is already up-to-date!\n🔹 Vector for 'king' :  [ 0.0268341   0.8061495  -0.0977395   0.17734371 -0.69379556  1.2658463\n -0.39709613 -3.2627854   0.906516    1.2353162  -0.13640618  0.36968157\n -1.8849266  -0.00536187 -0.0695098  -0.76161253 -1.0667338   0.15604101\n -0.90945417 -0.535907   -0.995781    0.5804178   0.8841474  -0.45629075\n  0.18422474 -2.053156   -1.396013   -0.7566671   2.1931703   0.01707104\n -0.43350992  0.16259736  1.0858573   0.06493995  1.5782845   2.0265596\n  1.0972726   2.2821429  -0.79041785  1.1447228   0.11419518 -0.70647645\n  0.79724866 -1.7105714   0.8798874  -0.92656654  0.5865015   0.04347868\n  1.420006   -0.16335727 -0.01687987  1.3019168   0.558438   -0.3571529\n  0.7174308  -0.37269962 -0.564663   -1.4222217  -0.02958049 -0.6511832\n  0.32959983  0.16041332  0.5099941   0.27247202  0.19495316 -0.7116366\n -0.37053826 -0.5766901   0.02674329 -0.72126216 -0.7465077  -0.80572706\n -0.5191011   1.3511171  -0.77218014  0.90203005 -0.8165621   0.7378166\n -0.27874386  0.9506413   0.7700951   1.2990146   0.90045106 -0.39030063\n -0.5856565   0.19266339 -0.32631522 -1.2003427  -2.1042364  -0.14274009\n -0.73578966 -0.74328905  1.6418818  -0.7159267  -1.1349908   1.0894924\n  1.2083291  -0.7746117  -0.82668704  0.737493  ]\n🔹 Most similar to 'queen' :  [('unseen', 0.9760584831237793), ('keen', 0.9732176661491394), ('Queen', 0.9702115654945374), ('Eileen', 0.9662582278251648), ('Zen', 0.9413174390792847), ('seen', 0.9338451027870178), ('oxen', 0.9296290874481201), ('Ten', 0.919633150100708), ('Men', 0.918999195098877), ('Eden', 0.9139904975891113)]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 🌟 Part 4 : Sequence Models 🌟","metadata":{}},{"cell_type":"markdown","source":"## Sub-part 2 : Sequence Models (RNN, LSTM, GRU) 🌐","metadata":{}},{"cell_type":"markdown","source":"### 🔄 Recurrent Neural Networks (RNN)","metadata":{}},{"cell_type":"markdown","source":"##### A recurrent neural network is a type of artificial neural network which uses sequential data or time series data by maintaining a hidden state that captures information about previous inputs.\n##### What are RNNs?\n* Sequential Data Handling: RNNs are ideal for tasks like time series analysis and language modeling\n* Hidden State: They maintain a memory of previous inputs in the hidden state.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, GRU, Dense\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:49:26.528783Z","iopub.execute_input":"2024-07-01T22:49:26.529618Z","iopub.status.idle":"2024-07-01T22:49:26.537081Z","shell.execute_reply.started":"2024-07-01T22:49:26.529576Z","shell.execute_reply":"2024-07-01T22:49:26.535781Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"sentences = [\n    \"I love sunny days\",\n    \"I hate rainy days\",\n    \"Sunshine makes me happy\",\n    \"Rainy days make me sad\",\n    \"I feel great on sunny days\",\n    \"Rainy days are gloomy and sad\"\n]","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:49:26.546498Z","iopub.execute_input":"2024-07-01T22:49:26.547527Z","iopub.status.idle":"2024-07-01T22:49:26.559369Z","shell.execute_reply.started":"2024-07-01T22:49:26.547476Z","shell.execute_reply":"2024-07-01T22:49:26.558049Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"markdown","source":"#### 🎯 Step 1: Tokenization and Padding","metadata":{}},{"cell_type":"code","source":"max_vocab_size = 1000\nmax_sequence_length = 10\n\n# Tokenize the sentences\ntokenizer = Tokenizer(num_words=max_vocab_size)\ntokenizer.fit_on_texts(sentences)\nsequences = tokenizer.texts_to_sequences(sentences)\nword_index = tokenizer.word_index\n\n# Pad the sequences\npadded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')\nprint(\"🔹 Padded Sequences:\\n\", padded_sequences)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:49:26.560944Z","iopub.execute_input":"2024-07-01T22:49:26.561657Z","iopub.status.idle":"2024-07-01T22:49:26.587113Z","shell.execute_reply.started":"2024-07-01T22:49:26.561619Z","shell.execute_reply":"2024-07-01T22:49:26.586003Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"🔹 Padded Sequences:\n [[ 2  7  4  1  0  0  0  0  0  0]\n [ 2  8  3  1  0  0  0  0  0  0]\n [ 9 10  5 11  0  0  0  0  0  0]\n [ 3  1 12  5  6  0  0  0  0  0]\n [ 2 13 14 15  4  1  0  0  0  0]\n [ 3  1 16 17 18  6  0  0  0  0]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### 🎢 Step 2: Preparing the labels","metadata":{}},{"cell_type":"code","source":"labels = np.array([1, 0, 1, 0, 1, 0])  # Positive: 1, Negative: 0","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:49:26.589151Z","iopub.execute_input":"2024-07-01T22:49:26.590160Z","iopub.status.idle":"2024-07-01T22:49:26.595741Z","shell.execute_reply.started":"2024-07-01T22:49:26.589940Z","shell.execute_reply":"2024-07-01T22:49:26.594578Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"markdown","source":"#### 🚀 Step 3: Build and train a Simple RNN model","metadata":{}},{"cell_type":"code","source":"print(\"🚀 Training a Simple RNN model...\")\n\nrnn_model = Sequential([\n    Embedding(input_dim=max_vocab_size, output_dim=32, input_length=max_sequence_length),\n    SimpleRNN(32, return_sequences=False),\n    Dense(1, activation='sigmoid')\n])\n\nrnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nrnn_model.summary()\n\n# Train the RNN model\nrnn_model.fit(padded_sequences, labels, epochs=5, verbose=2)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:49:26.597267Z","iopub.execute_input":"2024-07-01T22:49:26.602950Z","iopub.status.idle":"2024-07-01T22:49:28.854701Z","shell.execute_reply.started":"2024-07-01T22:49:26.602893Z","shell.execute_reply":"2024-07-01T22:49:28.853615Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"🚀 Training a Simple RNN model...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:86: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_3\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/5\n1/1 - 2s - 2s/step - accuracy: 0.6667 - loss: 0.7083\nEpoch 2/5\n1/1 - 0s - 26ms/step - accuracy: 0.6667 - loss: 0.6893\nEpoch 3/5\n1/1 - 0s - 26ms/step - accuracy: 0.6667 - loss: 0.6710\nEpoch 4/5\n1/1 - 0s - 59ms/step - accuracy: 0.8333 - loss: 0.6529\nEpoch 5/5\n1/1 - 0s - 27ms/step - accuracy: 0.8333 - loss: 0.6347\n","output_type":"stream"},{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7abb30cc9900>"},"metadata":{}}]},{"cell_type":"markdown","source":"### 🕰️ Long Short-Term Memory (LSTM) Networks","metadata":{}},{"cell_type":"markdown","source":"##### LSTMs are a type of RNN designed to overcome the vanishing gradient problem, allowing them to capture long-term dependencies in data.\n\n##### What's in LSTMs?\n* Memory Cells: LSTMs have special units called memory cells that can maintain information over long periods.\n* Gates: They use gates (input, forget, output) to control the flow of information.\n","metadata":{}},{"cell_type":"code","source":"print(\"🚀 Training an LSTM model...\")\n\nlstm_model = Sequential([\n    Embedding(input_dim=max_vocab_size, output_dim=32, input_length=max_sequence_length),\n    LSTM(32, return_sequences=False),\n    Dense(1, activation='sigmoid')\n])\n\nlstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nlstm_model.summary()\n\n# Train the LSTM model\nlstm_model.fit(padded_sequences, labels, epochs=5, verbose=2)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:49:28.855894Z","iopub.execute_input":"2024-07-01T22:49:28.856252Z","iopub.status.idle":"2024-07-01T22:49:31.469345Z","shell.execute_reply.started":"2024-07-01T22:49:28.856225Z","shell.execute_reply":"2024-07-01T22:49:31.468259Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"🚀 Training an LSTM model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_4\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/5\n1/1 - 2s - 2s/step - accuracy: 0.6667 - loss: 0.6929\nEpoch 2/5\n1/1 - 0s - 60ms/step - accuracy: 0.5000 - loss: 0.6921\nEpoch 3/5\n1/1 - 0s - 59ms/step - accuracy: 0.6667 - loss: 0.6913\nEpoch 4/5\n1/1 - 0s - 58ms/step - accuracy: 0.8333 - loss: 0.6905\nEpoch 5/5\n1/1 - 0s - 34ms/step - accuracy: 0.8333 - loss: 0.6896\n","output_type":"stream"},{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7ab9e8009a20>"},"metadata":{}}]},{"cell_type":"markdown","source":"### 🚪 Gated Recurrent Units (GRU)","metadata":{}},{"cell_type":"markdown","source":"##### GRUs are a variant of LSTMs that simplify the architecture by combining the forget and input gates into a single update gate\n##### What are GRUs?:\n* Simplified Structure: GRUs have fewer gates than LSTMs, making them faster to train\n* Performance: They often perform similarly to LSTMs for many tasks.","metadata":{}},{"cell_type":"code","source":"print(\"🚀 Training a GRU model...\")\n\ngru_model = Sequential([\n    Embedding(input_dim=max_vocab_size, output_dim=32, input_length=max_sequence_length),\n    GRU(32, return_sequences=False),\n    Dense(1, activation='sigmoid')\n])\n\ngru_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\ngru_model.summary()\n\ngru_model.fit(padded_sequences, labels, epochs=5, verbose=2)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:49:31.470852Z","iopub.execute_input":"2024-07-01T22:49:31.471212Z","iopub.status.idle":"2024-07-01T22:49:34.391430Z","shell.execute_reply.started":"2024-07-01T22:49:31.471184Z","shell.execute_reply":"2024-07-01T22:49:34.390155Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"🚀 Training a GRU model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_5\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_6 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/5\n1/1 - 3s - 3s/step - accuracy: 0.5000 - loss: 0.6933\nEpoch 2/5\n1/1 - 0s - 35ms/step - accuracy: 0.5000 - loss: 0.6929\nEpoch 3/5\n1/1 - 0s - 35ms/step - accuracy: 0.5000 - loss: 0.6926\nEpoch 4/5\n1/1 - 0s - 30ms/step - accuracy: 0.5000 - loss: 0.6924\nEpoch 5/5\n1/1 - 0s - 29ms/step - accuracy: 0.5000 - loss: 0.6921\n","output_type":"stream"},{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7aba1899cd90>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### 🎉 Comparing Model Performances","metadata":{}},{"cell_type":"code","source":"rnn_loss, rnn_accuracy = rnn_model.evaluate(padded_sequences, labels, verbose=0)\nlstm_loss, lstm_accuracy = lstm_model.evaluate(padded_sequences, labels, verbose=0)\ngru_loss, gru_accuracy = gru_model.evaluate(padded_sequences, labels, verbose=0)\n\nprint(f\"🔹 RNN Model Accuracy: {rnn_accuracy:.2f}\")\nprint(f\"🔹 LSTM Model Accuracy: {lstm_accuracy:.2f}\")\nprint(f\"🔹 GRU Model Accuracy: {gru_accuracy:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:49:34.394062Z","iopub.execute_input":"2024-07-01T22:49:34.394452Z","iopub.status.idle":"2024-07-01T22:49:36.229708Z","shell.execute_reply.started":"2024-07-01T22:49:34.394421Z","shell.execute_reply":"2024-07-01T22:49:36.228474Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"🔹 RNN Model Accuracy: 1.00\n🔹 LSTM Model Accuracy: 1.00\n🔹 GRU Model Accuracy: 0.50\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### 🎉 And that's a wrap on Sequence Models! You're now an RNN, LSTM, and GRU pro! 🎉","metadata":{}},{"cell_type":"markdown","source":"# 🌟 Part 5 : Attention Mechanisms and Transformers 🌟","metadata":{}},{"cell_type":"markdown","source":"### 🔍 Attention Mechanisms","metadata":{}},{"cell_type":"markdown","source":"##### Attention mechanisms allow models to focus on relevant parts of the input sequence when making predictions. They help improve performance on tasks like translation, summarization, and more.\n##### What is Attention?\n* Focus on Relevance: Attention helps the model focus on the most relevant parts of the input\n* Improves Performance: It boosts the performance of models on various NLP tasks.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Attention","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:49:36.231293Z","iopub.execute_input":"2024-07-01T22:49:36.231721Z","iopub.status.idle":"2024-07-01T22:49:36.239133Z","shell.execute_reply.started":"2024-07-01T22:49:36.231684Z","shell.execute_reply":"2024-07-01T22:49:36.237898Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"# dummy data\nX1 = np.random.rand(100, 10, 64)\nX2 = np.random.rand(100, 15, 64)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:49:36.240823Z","iopub.execute_input":"2024-07-01T22:49:36.241826Z","iopub.status.idle":"2024-07-01T22:49:36.251569Z","shell.execute_reply.started":"2024-07-01T22:49:36.241786Z","shell.execute_reply":"2024-07-01T22:49:36.250254Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"# model\nquery_input = Input(shape=(10, 64))\nvalue_input = Input(shape=(15, 64))\nattention_layer = Attention()([query_input, value_input])\ndense_output = Dense(1, activation='sigmoid')(attention_layer)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:49:36.253078Z","iopub.execute_input":"2024-07-01T22:49:36.255866Z","iopub.status.idle":"2024-07-01T22:49:36.280750Z","shell.execute_reply.started":"2024-07-01T22:49:36.255813Z","shell.execute_reply":"2024-07-01T22:49:36.279262Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"attention_model = Model(inputs=[query_input, value_input], outputs=dense_output)\nattention_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nattention_model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:49:36.282626Z","iopub.execute_input":"2024-07-01T22:49:36.283775Z","iopub.status.idle":"2024-07-01T22:49:36.324066Z","shell.execute_reply.started":"2024-07-01T22:49:36.283739Z","shell.execute_reply":"2024-07-01T22:49:36.322612Z"},"trusted":true},"execution_count":86,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_11\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_11\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_9       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_10      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ input_layer_9[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ input_layer_10[\u001b[38;5;34m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_8 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │         \u001b[38;5;34m65\u001b[0m │ attention_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_9       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_10      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ attention_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m65\u001b[0m (260.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> (260.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m65\u001b[0m (260.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> (260.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"### 🔧 Transformer Architecture","metadata":{}},{"cell_type":"markdown","source":"### Transformers use self-attention mechanisms to handle long-range dependencies more efficiently than RNNs. They have become the foundation for many state-of-the-art models.\n\n### What is a Transformer?\n* Self-Attention: Transformers use self-attention to weigh the importance of different words in a sentence\n* Parallel Processing: They can process words in parallel, making them faster than RNNs.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import LayerNormalization, Dropout\nfrom tensorflow.keras.layers import Embedding, MultiHeadAttention, Flatten","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:49:36.326141Z","iopub.execute_input":"2024-07-01T22:49:36.326791Z","iopub.status.idle":"2024-07-01T22:49:36.333583Z","shell.execute_reply.started":"2024-07-01T22:49:36.326750Z","shell.execute_reply":"2024-07-01T22:49:36.332339Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"input_seq = np.random.randint(1, 1000, (100, 10))","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:49:36.335174Z","iopub.execute_input":"2024-07-01T22:49:36.336582Z","iopub.status.idle":"2024-07-01T22:49:36.345838Z","shell.execute_reply.started":"2024-07-01T22:49:36.336537Z","shell.execute_reply":"2024-07-01T22:49:36.344355Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"# Transformer model\ninput_layer = Input(shape=(10,))\nembedding_layer = Embedding(input_dim=1000, output_dim=64)(input_layer)\nattention_output = MultiHeadAttention(num_heads=4, key_dim=64)(embedding_layer, embedding_layer)\nattention_output = Dropout(0.1)(attention_output)\nattention_output = LayerNormalization(epsilon=1e-6)(attention_output + embedding_layer)\noutput_layer = Dense(1, activation='sigmoid')(Flatten()(attention_output))","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:49:36.347606Z","iopub.execute_input":"2024-07-01T22:49:36.348085Z","iopub.status.idle":"2024-07-01T22:49:36.425413Z","shell.execute_reply.started":"2024-07-01T22:49:36.348046Z","shell.execute_reply":"2024-07-01T22:49:36.424030Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"transformer_model = Model(inputs=input_layer, outputs=output_layer)\ntransformer_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:49:36.428028Z","iopub.execute_input":"2024-07-01T22:49:36.428505Z","iopub.status.idle":"2024-07-01T22:49:36.446512Z","shell.execute_reply.started":"2024-07-01T22:49:36.428465Z","shell.execute_reply":"2024-07-01T22:49:36.445348Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"transformer_model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-07-01T22:49:36.447860Z","iopub.execute_input":"2024-07-01T22:49:36.448373Z","iopub.status.idle":"2024-07-01T22:49:36.483131Z","shell.execute_reply.started":"2024-07-01T22:49:36.448327Z","shell.execute_reply":"2024-07-01T22:49:36.481909Z"},"trusted":true},"execution_count":91,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_13\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_13\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_11      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding_7         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m64,000\u001b[0m │ input_layer_11[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m66,368\u001b[0m │ embedding_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ embedding_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│                     │                   │            │ embedding_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m128\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m640\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_9 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m641\u001b[0m │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_11      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding_7         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">64,000</span> │ input_layer_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ embedding_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ embedding_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│                     │                   │            │ embedding_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">641</span> │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m131,137\u001b[0m (512.25 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">131,137</span> (512.25 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m131,137\u001b[0m (512.25 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">131,137</span> (512.25 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"### ⚙️ Implementing Transformers","metadata":{}},{"cell_type":"markdown","source":"##### We will use HuggingFace's Transformers libraries to implememt our tasks\n\n##### please refer to following [notebooks](https://huggingface.co/docs/transformers/en/notebooks)","metadata":{}},{"cell_type":"code","source":"! pip install transformers\n! pip install transformers datasets\n! pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2024-07-10T21:51:20.825942Z","iopub.execute_input":"2024-07-10T21:51:20.827294Z","iopub.status.idle":"2024-07-10T21:52:09.929719Z","shell.execute_reply.started":"2024-07-10T21:51:20.827229Z","shell.execute_reply":"2024-07-10T21:52:09.928281Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.2)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.18.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.22.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\nimport numpy as np\nimport evaluate\n\n# IMDB reviews dataset\ndataset = load_dataset(\"imdb\")\nprint(\"Sample review:\", dataset[\"train\"][0])\n\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n\ntokenized_datasets = dataset.map(tokenize_function, batched=True, num_proc=4)\nmodel = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)\n\nsmall_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(100))\nsmall_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(100))\n\nmetric = evaluate.load(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)\n\ntraining_args = TrainingArguments(\n    output_dir=\"test_trainer\",\n    evaluation_strategy=\"epoch\",\n    per_device_train_batch_size=4,  # Smaller batch size to fit memory\n    per_device_eval_batch_size=4,   # Smaller batch size to fit memory\n    num_train_epochs=1,             # Reduce epochs for quick results\n    weight_decay=0.01,\n    logging_dir=\"logs\",\n    report_to=[],                   # Disable wandb\n    dataloader_num_workers=2,       # Reduce number of workers\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=small_train_dataset,\n    eval_dataset=small_eval_dataset,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()\nresults = trainer.evaluate()\nprint(\"Evaluation Results:\", results)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-10T21:52:09.932495Z","iopub.execute_input":"2024-07-10T21:52:09.932959Z","iopub.status.idle":"2024-07-10T22:01:36.406310Z","shell.execute_reply.started":"2024-07-10T21:52:09.932916Z","shell.execute_reply":"2024-07-10T22:01:36.404650Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Sample review: {'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.', 'label': 0}\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [25/25 07:27, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.684495</td>\n      <td>0.580000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [25/25 01:29]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"Evaluation Results: {'eval_loss': 0.6844951510429382, 'eval_accuracy': 0.58, 'eval_runtime': 94.4997, 'eval_samples_per_second': 1.058, 'eval_steps_per_second': 0.265, 'epoch': 1.0}\n","output_type":"stream"}]},{"cell_type":"code","source":"# from datasets import load_dataset\n# from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n# import numpy as np\n# import evaluate\n\n# # the Yelp reviews dataset\n# dataset = load_dataset(\"yelp_review_full\")\n# print(\"Sample review:\", dataset[\"train\"][100])\n\n# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n\n# def tokenize_function(examples):\n#     return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n\n# tokenized_datasets = dataset.map(tokenize_function, batched=True)\n\n# model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)\n# small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n# small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))\n\n# metric = evaluate.load(\"accuracy\")\n\n# def compute_metrics(eval_pred):\n#     logits, labels = eval_pred\n#     predictions = np.argmax(logits, axis=-1)\n#     return metric.compute(predictions=predictions, references=labels)\n\n# training_args = TrainingArguments(\n#     output_dir=\"test_trainer\",\n#     evaluation_strategy=\"epoch\",\n#     per_device_train_batch_size=8,\n#     per_device_eval_batch_size=8,\n#     num_train_epochs=3,\n#     weight_decay=0.01,\n#     logging_dir=\"logs\",\n#     report_to=[],  # Disable wandb\n# )\n\n# trainer = Trainer(\n#     model=model,\n#     args=training_args,\n#     train_dataset=small_train_dataset,\n#     eval_dataset=small_eval_dataset,\n#     compute_metrics=compute_metrics,\n# )\n\n# # please uncomment below code lines to train and see results\n\n# # trainer.train()\n# # results = trainer.evaluate()\n# # print(\"Evaluation Results:\", results)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-10T21:21:33.141558Z","iopub.execute_input":"2024-07-10T21:21:33.142090Z","iopub.status.idle":"2024-07-10T21:29:54.597721Z","shell.execute_reply.started":"2024-07-10T21:21:33.142052Z","shell.execute_reply":"2024-07-10T21:29:54.596373Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/6.72k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1ed60a0d81a4473b496a46cac30ee2e"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 299M/299M [00:01<00:00, 220MB/s]  \nDownloading data: 100%|██████████| 23.5M/23.5M [00:00<00:00, 80.1MB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/650000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc6fb20dbb514cef87816cc2f1c0e930"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56f0a0ab20ea45c59668f18de19736a5"}},"metadata":{}},{"name":"stdout","text":"Sample review: {'label': 0, 'text': 'My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\\\nThe cashier took my friends\\'s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\\'s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\\\\"serving off their orders\\\\\" when they didn\\'t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\\\nThe manager was rude when giving me my order. She didn\\'t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\\\nI\\'ve eaten at various McDonalds restaurants for over 30 years. I\\'ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!'}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52a79244c9804c2aab8b290c73951671"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19054dd4354645ecab001609eb2df401"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97dde01945ca423981c40653f1052542"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ecedc1d0aec4c55a3753802b22a5e70"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/650000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e6f3ace79dc44bfa8f5f55d71793314"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d843b7c7e300470baa063175b6e888f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee764b296c7c416899c3c352338ffab8"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b04dfac88a5f4ec188630253d885a0ad"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 🌟 Part 6 : BERT and Transformer-based Models 🌟","metadata":{}},{"cell_type":"markdown","source":"### 🧠 BERT (Bidirectional Encoder Representations from Transformers)","metadata":{}},{"cell_type":"markdown","source":"##### BERT is a model that understands the context of words in a sentence bidirectionally, in this every output element is connected to every input element, and the weightings between them are dynamically calculated based upon their connection\n\n##### What is BERT?\n* Bidirectional Understanding: BERT looks at the context from both left and right.\n* Pre-training and Fine-tuning: BERT is pre-trained on large corpora and then fine-tuned for specific tasks.\n\n[paper](https://arxiv.org/abs/1810.04805) ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom transformers import BertTokenizer, TFBertForSequenceClassification\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\nsentences = [\"BERT is fantastic!\", \"I love natural language processing.\"]\ninputs = tokenizer(sentences, return_tensors='tf', padding=True, truncation=True, max_length=128)\noutputs = model(inputs['input_ids'])\nlogits = outputs.logits\nprobs = tf.nn.softmax(logits, axis=-1).numpy()\n\nfor sentence, prob in zip(sentences, probs):\n    print(f\"Sentence: '{sentence}'\")\n    print(f\"Probabilities: {prob}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T04:25:43.847033Z","iopub.execute_input":"2024-07-02T04:25:43.847618Z","iopub.status.idle":"2024-07-02T04:25:47.842112Z","shell.execute_reply.started":"2024-07-02T04:25:43.847578Z","shell.execute_reply":"2024-07-02T04:25:47.840723Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n\nSome weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Sentence: 'BERT is fantastic!'\nProbabilities: [0.47343397 0.526566  ]\nSentence: 'I love natural language processing.'\nProbabilities: [0.4088196 0.5911804]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 🔄 Variants of BERT","metadata":{}},{"cell_type":"markdown","source":"#### 1. 📊 RoBERTa (Robustly Optimized BERT Pre-training Approach)\n*  Improvements: More training data and longer training times.\n*  Usage: Similar to BERT but often performs better.","metadata":{}},{"cell_type":"code","source":"from transformers import RobertaTokenizer, TFRobertaForSequenceClassification\nimport tensorflow as tf\n\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base')\nroberta_model = TFRobertaForSequenceClassification.from_pretrained('roberta-base')\n\nsentences = [\"RoBERTa is a powerful model!\", \"I love exploring NLP models.\"]\ninputs = tokenizer(sentences, return_tensors='tf', padding=True, truncation=True, max_length=128)\noutputs = roberta_model(inputs['input_ids'])\nlogits = outputs.logits\n\nprobabilities = tf.nn.softmax(logits, axis=-1)\n\nprint(\"Logits:\", logits)\nprint(\"Probabilities:\", probabilities)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T04:33:49.758678Z","iopub.execute_input":"2024-07-02T04:33:49.759139Z","iopub.status.idle":"2024-07-02T04:33:54.105794Z","shell.execute_reply.started":"2024-07-02T04:33:49.759108Z","shell.execute_reply":"2024-07-02T04:33:54.104520Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights or buffers of the TF 2.0 model TFRobertaForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Logits: tf.Tensor(\n[[0.09057087 0.13585457]\n [0.09924239 0.1302266 ]], shape=(2, 2), dtype=float32)\nProbabilities: tf.Tensor(\n[[0.48868102 0.511319  ]\n [0.49225459 0.50774544]], shape=(2, 2), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### 2. 📊 DistilBERT (Distilled BERT)\n*  Lightweight: Smaller and faster than BERT with comparable performance.\n*  Usage: Ideal for resource-constrained environments.\n\n[blog](https://huggingface.co/blog/sentiment-analysis-python) ","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\nsentiment_pipeline = pipeline(\"sentiment-analysis\")\ndata = [\"I love you\", \"I hate you\"]\nsentiment_pipeline(data)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T04:18:34.392815Z","iopub.execute_input":"2024-07-02T04:18:34.393308Z","iopub.status.idle":"2024-07-02T04:18:39.245838Z","shell.execute_reply.started":"2024-07-02T04:18:34.393267Z","shell.execute_reply":"2024-07-02T04:18:39.244750Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a3ec0b2d9b548ce968b5ebcd41fb60e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3b1fe0db54a41adb8ee15c071c8a3a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1aae509331b941dfbc896b5f53ff4b73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e52e4ac5f3b41558b469e4c87e48c82"}},"metadata":{}},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"[{'label': 'POSITIVE', 'score': 0.9998656511306763},\n {'label': 'NEGATIVE', 'score': 0.9991129040718079}]"},"metadata":{}}]},{"cell_type":"code","source":"specific_model = pipeline(model=\"finiteautomata/bertweet-base-sentiment-analysis\")\nspecific_model(data)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T04:18:42.152028Z","iopub.execute_input":"2024-07-02T04:18:42.153100Z","iopub.status.idle":"2024-07-02T04:18:47.204819Z","shell.execute_reply.started":"2024-07-02T04:18:42.153046Z","shell.execute_reply":"2024-07-02T04:18:47.203082Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/949 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"930ba1b4332145a692edc75935bf1186"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/540M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb4e7cef07e14397819c373d5d3d646b"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/338 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e71b226fec846b5b7923834a1eca6d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/843k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc3771d23c584a3d84cdca64c27b8d72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"bpe.codes:   0%|          | 0.00/1.08M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e4f560d10bd43b592847977ef9c84aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/22.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5bf13019f18463e8447bd4df96ebdd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a3970aebd44483bb4bf2a0e7d1eed93"}},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"[{'label': 'POS', 'score': 0.9916695356369019},\n {'label': 'NEG', 'score': 0.9806600213050842}]"},"metadata":{}}]},{"cell_type":"markdown","source":"#### 3. 📊 GPT (Generative Pre-trained Transformer)\n##### GPT is a powerful model known for its text generation capabilities. It predicts the next word in a sequence, this model is great for coherent tasks.","metadata":{}},{"cell_type":"markdown","source":"#####  is GPT?\n* Unidirectional: GPT processes text from left to right.\n* Text Generation: Ideal for creating human-like text.","metadata":{}},{"cell_type":"code","source":"from transformers import GPT2Tokenizer, TFGPT2LMHeadModel\n\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\ngpt2_model = TFGPT2LMHeadModel.from_pretrained('gpt2')\n\ninputs = tokenizer(\"Once upon a time,\", return_tensors='tf')\n\n# Generate text\noutputs = gpt2_model.generate(inputs['input_ids'], max_length=50)\nprint(tokenizer.decode(outputs[0]))\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T04:27:25.097280Z","iopub.execute_input":"2024-07-02T04:27:25.097944Z","iopub.status.idle":"2024-07-02T04:27:51.829548Z","shell.execute_reply.started":"2024-07-02T04:27:25.097895Z","shell.execute_reply":"2024-07-02T04:27:51.828150Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"102bfa9c7c2840acb449840469f68d9d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00b82c97b6a84a7ab6144a94d2d15931"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04fe051190034a87bc9bea012918cf2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da47fa71b8f24ac59e00c4f9b0343843"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"964b4d3b4dbb46f3be3a0be7811a9da8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a5283204a8a4a0195014619c4408710"}},"metadata":{}},{"name":"stderr","text":"All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n\nAll the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Once upon a time, the world was a place of great beauty and great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great danger, and the world was a\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### 4. 📊 (Text-To-Text Transfer Transformer)\n##### T5 treats all NLP tasks as a text-to-text problem, making it incredibly versatile.\n\n##### What is T5?\n* Text-to-Text Framework: Converts every task\n* Versatility: Can handle tasks like translation, summarization, and more.","metadata":{}},{"cell_type":"code","source":"from transformers import T5Tokenizer, TFT5ForConditionalGeneration\n\ntokenizer = T5Tokenizer.from_pretrained('t5-small')\nt5_model = TFT5ForConditionalGeneration.from_pretrained('t5-small')\n\ninputs = tokenizer(\"translate English to French: The house is wonderful.\", return_tensors='tf')\n\n# Generate translation\noutputs = t5_model.generate(inputs['input_ids'], max_length=50)\nprint(tokenizer.decode(outputs[0]))","metadata":{"execution":{"iopub.status.busy":"2024-07-02T04:28:24.290634Z","iopub.execute_input":"2024-07-02T04:28:24.291217Z","iopub.status.idle":"2024-07-02T04:28:31.729609Z","shell.execute_reply.started":"2024-07-02T04:28:24.291173Z","shell.execute_reply":"2024-07-02T04:28:31.728163Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35d70527c5d4455ea35d4c7a01e01f18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa0151aa28be4b7fbfd4d44310be467f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e1abb0cf20c4a789c6942e8b07a6116"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89d768fbc71b488eb26e5a9a441045b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2dedcd14c7bd41838b2223b0575266d6"}},"metadata":{}},{"name":"stderr","text":"All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n\nAll the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1719894510.061058      33 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n2024-07-02 04:28:30.063012: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n","output_type":"stream"},{"name":"stdout","text":"<pad> La maison est merveilleuse.</s>\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 📚 Other Transformer-based Models","metadata":{}},{"cell_type":"markdown","source":"##### There are many other Transformer-based models with unique features and improvements.","metadata":{}},{"cell_type":"markdown","source":"##### XLNet\n* Permutated Language Model: Captures bidirectional context without using masking.","metadata":{}},{"cell_type":"markdown","source":"#####  ELECTRA\n* Discriminative Pre-training: Focuses on distinguishing real input tokens from corrupted ones.","metadata":{}},{"cell_type":"markdown","source":"Please also check for many more models! https://huggingface.co/docs/transformers/index","metadata":{}},{"cell_type":"markdown","source":"# 🌟 Part 7 : Advanced Embeddings and Contextualized Word Representations 🌟","metadata":{}},{"cell_type":"markdown","source":"##### I mentioned this part because we should look into the models that take word embeddings to the next level by considering the context in which words appear.","metadata":{}},{"cell_type":"markdown","source":"### 🧠 ELMo (Embeddings from Language Models)","metadata":{}},{"cell_type":"markdown","source":"##### ELMo provides deep contextualized word representations that model both complex characteristics of word use (e.g., syntax and semantics) and how these uses vary across linguistic contexts.","metadata":{}},{"cell_type":"markdown","source":"##### What is ELMo?\n* Contextualized Representations: Captures context-specific meanings of words.\n* Deep Bidirectional LSTMs: Utilizes stacked bidirectional LSTM networks","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_hub as hub\nimport numpy as np\nelmo = hub.load(\"https://tfhub.dev/google/elmo/2\").signatures[\"default\"]\nx = [\"Hi my friend\"]\nembeddings = elmo(tf.constant(x))[\"elmo\"]","metadata":{"execution":{"iopub.status.busy":"2024-07-03T00:38:10.747697Z","iopub.execute_input":"2024-07-03T00:38:10.748112Z","iopub.status.idle":"2024-07-03T00:38:34.145171Z","shell.execute_reply.started":"2024-07-03T00:38:10.748080Z","shell.execute_reply":"2024-07-03T00:38:34.144077Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"embeddings","metadata":{"execution":{"iopub.status.busy":"2024-07-03T00:40:18.870441Z","iopub.execute_input":"2024-07-03T00:40:18.870952Z","iopub.status.idle":"2024-07-03T00:40:18.883692Z","shell.execute_reply.started":"2024-07-03T00:40:18.870914Z","shell.execute_reply":"2024-07-03T00:40:18.882436Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(1, 3, 1024), dtype=float32, numpy=\narray([[[-0.7205106 , -0.27990717, -0.77356255, ..., -0.24703969,\n         -0.83581793, -0.19747892],\n        [ 0.1850021 , -0.12270828, -0.35163125, ...,  0.14234737,\n          0.08479907, -0.1170994 ],\n        [-0.49985927, -0.88964033, -0.3012452 , ...,  0.15846598,\n          0.05210415,  0.25386304]]], dtype=float32)>"},"metadata":{}}]},{"cell_type":"markdown","source":"### 🚀 ULMFiT (Universal Language Model Fine-tuning)","metadata":{}},{"cell_type":"markdown","source":"##### ULMFiT fine-tunes a pre-trained language model on a target task, achieving state-of-the-art results with minimal task-specific data.\n\n##### What is ULMFiT?\n* Transfer Learning: Fine-tune on target tasks.\n* Flexibility: Adapts to various NLP tasks with minimal data.\n\n[code](https://www.geeksforgeeks.org/universal-language-model-fine-tuning-ulmfit-in-nlp/)","metadata":{}},{"cell_type":"code","source":"!pip install fastai","metadata":{"execution":{"iopub.status.busy":"2024-07-03T00:57:10.182108Z","iopub.execute_input":"2024-07-03T00:57:10.183168Z","iopub.status.idle":"2024-07-03T00:57:25.373166Z","shell.execute_reply.started":"2024-07-03T00:57:10.183126Z","shell.execute_reply":"2024-07-03T00:57:25.371698Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Requirement already satisfied: fastai in /opt/conda/lib/python3.10/site-packages (2.7.14)\nRequirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (from fastai) (23.3.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from fastai) (21.3)\nRequirement already satisfied: fastdownload<2,>=0.0.5 in /opt/conda/lib/python3.10/site-packages (from fastai) (0.0.7)\nRequirement already satisfied: fastcore<1.6,>=1.5.29 in /opt/conda/lib/python3.10/site-packages (from fastai) (1.5.29)\nRequirement already satisfied: torchvision>=0.11 in /opt/conda/lib/python3.10/site-packages (from fastai) (0.13.1)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from fastai) (3.7.5)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from fastai) (2.2.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from fastai) (2.31.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from fastai) (6.0.1)\nRequirement already satisfied: fastprogress>=0.2.4 in /opt/conda/lib/python3.10/site-packages (from fastai) (1.0.3)\nRequirement already satisfied: pillow>=9.0.0 in /opt/conda/lib/python3.10/site-packages (from fastai) (9.5.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from fastai) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from fastai) (1.11.4)\nRequirement already satisfied: spacy<4 in /opt/conda/lib/python3.10/site-packages (from fastai) (3.3.3)\nRequirement already satisfied: torch<2.3,>=1.10 in /opt/conda/lib/python3.10/site-packages (from fastai) (1.12.1)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (3.0.9)\nRequirement already satisfied: thinc<8.1.0,>=8.0.14 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (8.0.17)\nRequirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (0.7.11)\nRequirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (0.10.1)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (2.0.10)\nRequirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (0.4.2)\nRequirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (0.11.0)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (6.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (4.66.1)\nRequirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (1.26.4)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (1.8.2)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (3.1.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (69.0.3)\nRequirement already satisfied: typing-extensions<4.6.0,>=3.7.4.1 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (4.5.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai) (3.3.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->fastai) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->fastai) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->fastai) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->fastai) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->fastai) (2024.2.2)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fastai) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fastai) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fastai) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fastai) (1.4.5)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fastai) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->fastai) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->fastai) (2023.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->fastai) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->fastai) (3.2.0)\nRequirement already satisfied: pathlib-abc==0.1.1 in /opt/conda/lib/python3.10/site-packages (from pathy>=0.3.5->spacy<4->fastai) (0.1.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->fastai) (1.16.0)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.5.0,>=0.3.0->spacy<4->fastai) (8.1.7)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<4->fastai) (2.1.3)\n","output_type":"stream"}]},{"cell_type":"code","source":"from fastai.text.all import *\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-07-03T00:57:54.809910Z","iopub.execute_input":"2024-07-03T00:57:54.810446Z","iopub.status.idle":"2024-07-03T00:57:54.818709Z","shell.execute_reply.started":"2024-07-03T00:57:54.810399Z","shell.execute_reply":"2024-07-03T00:57:54.817307Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"path = untar_data(URLs.AG_NEWS)\n\ndf = pd.read_csv(path/'train.csv', header=None)\ndf.columns = ['label', 'title', 'description']\ndf['text'] = df['title'] + ' ' + df['description']\ndf.to_csv(path/'train_modified.csv', index=False)\n\ndls = TextDataLoaders.from_csv(path, 'train_modified.csv', text_col='text', label_col='label', valid_pct=0.2, is_lm=False)\nlearn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)\n \n# one cycle\nlearn.fit_one_cycle(1, 1e-2)\naccuracy = learn.validate()[1]\nprint(f\"Accuracy: {accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-03T00:58:40.386568Z","iopub.execute_input":"2024-07-03T00:58:40.386985Z","iopub.status.idle":"2024-07-03T02:05:26.936092Z","shell.execute_reply.started":"2024-07-03T00:58:40.386954Z","shell.execute_reply":"2024-07-03T02:05:26.934513Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      <progress value='105070592' class='' max='105067061' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      100.00% [105070592/105067061 00:06&lt;00:00]\n    </div>\n    "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.480479</td>\n      <td>0.333502</td>\n      <td>0.879708</td>\n      <td>54:32</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.8797083497047424\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 🛠️ Contextualized Embeddings in Practice","metadata":{}},{"cell_type":"markdown","source":"##### Word embedding techniques create global word embeddings based on the unique words in the entire vocabulary of the documents, without considering the different contexts in which words appear. These techniques learn similar representations for words that frequently appear close to each other in the text.\n\n\n##### Contextual embedding methods, on the other hand, capture the semantics of word sequences by taking into account the context provided by the entire sequence of words in the documents.\n\n\n\n\n\n","metadata":{}},{"cell_type":"code","source":"from transformers import BertTokenizer, TFBertForSequenceClassification\nimport tensorflow as tf\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nbert_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')\n\nsentences = [\"I love using BERT for NLP tasks!\", \"Transformers are powerful.\"]\ninputs = tokenizer(sentences, return_tensors='tf', padding=True, truncation=True, max_length=128)\noutputs = bert_model(inputs['input_ids'])\nlogits = outputs.logits\nprobabilities = tf.nn.softmax(logits, axis=-1)\n\nprint(\"Logits:\", logits)\nprint(\"Probabilities:\", probabilities)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-03T02:09:27.829612Z","iopub.execute_input":"2024-07-03T02:09:27.830051Z","iopub.status.idle":"2024-07-03T02:09:54.195558Z","shell.execute_reply.started":"2024-07-03T02:09:27.830018Z","shell.execute_reply":"2024-07-03T02:09:54.194416Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/511M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6e9826e9d18497694464b29568a4c9a"}},"metadata":{}},{"name":"stderr","text":"Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertForSequenceClassification: ['bert/encoder/layer_._11/output/LayerNorm/gamma:0', 'bert/encoder/layer_._1/attention/self/key/kernel:0', 'bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._11/attention/output/dense/bias:0', 'bert/encoder/layer_._0/output/dense/bias:0', 'bert/encoder/layer_._5/output/dense/kernel:0', 'bert/encoder/layer_._0/attention/self/key/kernel:0', 'bert/encoder/layer_._6/intermediate/dense/kernel:0', 'bert/encoder/layer_._6/attention/self/value/bias:0', 'bert/encoder/layer_._0/intermediate/dense/bias:0', 'bert/encoder/layer_._4/attention/self/query/bias:0', 'bert/encoder/layer_._6/attention/self/value/kernel:0', 'bert/encoder/layer_._6/attention/self/query/kernel:0', 'bert/encoder/layer_._10/output/dense/kernel:0', 'bert/encoder/layer_._4/attention/self/key/kernel:0', 'bert/encoder/layer_._1/attention/output/dense/kernel:0', 'bert/encoder/layer_._3/attention/self/query/kernel:0', 'bert/encoder/layer_._1/attention/self/value/kernel:0', 'bert/encoder/layer_._1/output/dense/kernel:0', 'bert/encoder/layer_._11/output/dense/kernel:0', 'bert/encoder/layer_._0/intermediate/dense/kernel:0', 'bert/encoder/layer_._7/output/LayerNorm/beta:0', 'bert/encoder/layer_._4/intermediate/dense/kernel:0', 'bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._10/intermediate/dense/bias:0', 'bert/encoder/layer_._11/attention/self/value/bias:0', 'bert/encoder/layer_._9/attention/self/query/kernel:0', 'bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._5/attention/self/query/kernel:0', 'bert/encoder/layer_._5/attention/self/value/bias:0', 'bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._10/attention/self/key/kernel:0', 'bert/encoder/layer_._11/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._11/attention/self/query/bias:0', 'bert/encoder/layer_._2/intermediate/dense/bias:0', 'bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._0/attention/self/query/kernel:0', 'bert/encoder/layer_._10/output/dense/bias:0', 'bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'bert/encoder/layer_._7/attention/self/key/kernel:0', 'bert/encoder/layer_._10/output/LayerNorm/beta:0', 'bert/encoder/layer_._8/attention/self/query/bias:0', 'bert/encoder/layer_._3/output/LayerNorm/beta:0', 'bert/encoder/layer_._9/intermediate/dense/bias:0', 'bert/encoder/layer_._7/attention/self/value/bias:0', 'bert/encoder/layer_._11/intermediate/dense/bias:0', 'bert/encoder/layer_._8/attention/output/dense/kernel:0', 'bert/encoder/layer_._3/attention/self/key/kernel:0', 'bert/encoder/layer_._3/intermediate/dense/bias:0', 'bert/encoder/layer_._8/attention/self/value/bias:0', 'bert/encoder/layer_._8/intermediate/dense/kernel:0', 'bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'bert/encoder/layer_._9/output/LayerNorm/beta:0', 'bert/encoder/layer_._11/attention/self/key/bias:0', 'bert/encoder/layer_._6/attention/self/query/bias:0', 'bert/encoder/layer_._6/output/LayerNorm/beta:0', 'bert/encoder/layer_._0/attention/output/dense/kernel:0', 'bert/encoder/layer_._5/output/LayerNorm/beta:0', 'bert/pooler/dense/kernel:0', 'bert/encoder/layer_._8/attention/output/dense/bias:0', 'bert/encoder/layer_._1/output/dense/bias:0', 'bert/encoder/layer_._5/intermediate/dense/kernel:0', 'bert/encoder/layer_._5/attention/self/query/bias:0', 'bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._7/attention/self/query/bias:0', 'bert/encoder/layer_._8/attention/self/value/kernel:0', 'bert/encoder/layer_._2/intermediate/dense/kernel:0', 'bert/embeddings/position_embeddings/embeddings:0', 'bert/encoder/layer_._10/attention/self/query/kernel:0', 'bert/encoder/layer_._9/attention/output/dense/kernel:0', 'bert/encoder/layer_._2/attention/self/key/kernel:0', 'bert/encoder/layer_._10/attention/self/query/bias:0', 'bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._8/output/dense/kernel:0', 'bert/encoder/layer_._3/attention/output/dense/bias:0', 'bert/encoder/layer_._5/attention/self/key/kernel:0', 'bert/encoder/layer_._4/output/dense/kernel:0', 'bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._2/attention/output/dense/kernel:0', 'bert/encoder/layer_._3/output/dense/kernel:0', 'bert/encoder/layer_._2/output/dense/kernel:0', 'bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._4/attention/self/value/bias:0', 'bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'bert/encoder/layer_._10/attention/output/dense/kernel:0', 'bert/encoder/layer_._1/attention/self/value/bias:0', 'bert/encoder/layer_._5/output/dense/bias:0', 'bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._3/attention/self/query/bias:0', 'bert/encoder/layer_._2/attention/self/key/bias:0', 'bert/encoder/layer_._9/attention/self/key/bias:0', 'bert/encoder/layer_._6/output/dense/kernel:0', 'bert/encoder/layer_._7/attention/self/query/kernel:0', 'bert/encoder/layer_._11/attention/output/dense/kernel:0', 'bert/embeddings/word_embeddings/weight:0', 'bert/encoder/layer_._1/intermediate/dense/kernel:0', 'bert/encoder/layer_._9/output/dense/kernel:0', 'bert/encoder/layer_._6/attention/self/key/kernel:0', 'bert/encoder/layer_._9/intermediate/dense/kernel:0', 'bert/encoder/layer_._8/intermediate/dense/bias:0', 'bert/encoder/layer_._0/attention/self/value/bias:0', 'bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._6/attention/self/key/bias:0', 'bert/encoder/layer_._10/attention/self/value/bias:0', 'bert/encoder/layer_._7/attention/output/dense/kernel:0', 'bert/encoder/layer_._4/attention/self/key/bias:0', 'bert/encoder/layer_._1/attention/self/key/bias:0', 'bert/encoder/layer_._0/attention/output/dense/bias:0', 'bert/encoder/layer_._2/attention/self/value/bias:0', 'bert/encoder/layer_._4/attention/output/dense/bias:0', 'bert/encoder/layer_._9/attention/output/dense/bias:0', 'bert/encoder/layer_._3/intermediate/dense/kernel:0', 'bert/encoder/layer_._7/attention/self/value/kernel:0', 'bert/encoder/layer_._9/attention/self/value/bias:0', 'bert/encoder/layer_._5/attention/output/dense/bias:0', 'bert/encoder/layer_._9/attention/self/value/kernel:0', 'bert/encoder/layer_._3/attention/self/value/kernel:0', 'bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'bert/encoder/layer_._0/output/dense/kernel:0', 'bert/encoder/layer_._2/output/LayerNorm/beta:0', 'bert/encoder/layer_._1/attention/self/query/bias:0', 'bert/encoder/layer_._11/attention/self/query/kernel:0', 'bert/encoder/layer_._5/intermediate/dense/bias:0', 'bert/encoder/layer_._6/attention/output/dense/bias:0', 'bert/encoder/layer_._11/intermediate/dense/kernel:0', 'bert/encoder/layer_._1/attention/self/query/kernel:0', 'bert/encoder/layer_._6/output/dense/bias:0', 'bert/encoder/layer_._0/output/LayerNorm/beta:0', 'bert/encoder/layer_._2/attention/self/value/kernel:0', 'bert/encoder/layer_._6/attention/output/dense/kernel:0', 'bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._4/output/dense/bias:0', 'bert/encoder/layer_._5/attention/self/value/kernel:0', 'bert/embeddings/LayerNorm/gamma:0', 'bert/encoder/layer_._4/output/LayerNorm/beta:0', 'bert/encoder/layer_._7/attention/output/dense/bias:0', 'bert/encoder/layer_._8/attention/self/query/kernel:0', 'bert/encoder/layer_._8/attention/self/key/bias:0', 'bert/encoder/layer_._1/attention/output/dense/bias:0', 'bert/encoder/layer_._8/output/dense/bias:0', 'bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._6/intermediate/dense/bias:0', 'bert/encoder/layer_._1/output/LayerNorm/beta:0', 'bert/encoder/layer_._3/attention/output/dense/kernel:0', 'bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._3/output/dense/bias:0', 'bert/embeddings/LayerNorm/beta:0', 'bert/encoder/layer_._9/output/dense/bias:0', 'bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._10/attention/self/key/bias:0', 'bert/encoder/layer_._7/intermediate/dense/bias:0', 'bert/encoder/layer_._8/output/LayerNorm/beta:0', 'bert/encoder/layer_._11/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'bert/encoder/layer_._2/attention/self/query/bias:0', 'bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._2/attention/self/query/kernel:0', 'bert/encoder/layer_._2/attention/output/dense/bias:0', 'bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'bert/encoder/layer_._5/attention/output/dense/kernel:0', 'bert/encoder/layer_._4/attention/self/value/kernel:0', 'bert/encoder/layer_._7/output/dense/kernel:0', 'bert/encoder/layer_._11/attention/self/key/kernel:0', 'bert/encoder/layer_._4/attention/self/query/kernel:0', 'bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'bert/encoder/layer_._7/intermediate/dense/kernel:0', 'bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._0/attention/self/key/bias:0', 'bert/encoder/layer_._0/attention/self/value/kernel:0', 'bert/encoder/layer_._11/output/LayerNorm/beta:0', 'bert/encoder/layer_._10/attention/output/dense/bias:0', 'bert/encoder/layer_._7/output/dense/bias:0', 'bert/encoder/layer_._10/intermediate/dense/kernel:0', 'bert/embeddings/token_type_embeddings/embeddings:0', 'bert/encoder/layer_._8/attention/self/key/kernel:0', 'bert/encoder/layer_._4/attention/output/dense/kernel:0', 'bert/encoder/layer_._5/attention/self/key/bias:0', 'bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'bert/encoder/layer_._0/attention/self/query/bias:0', 'bert/encoder/layer_._4/intermediate/dense/bias:0', 'bert/encoder/layer_._11/output/dense/bias:0', 'bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'bert/encoder/layer_._2/output/dense/bias:0', 'bert/encoder/layer_._9/attention/self/key/kernel:0', 'bert/encoder/layer_._3/attention/self/key/bias:0', 'bert/encoder/layer_._10/attention/self/value/kernel:0', 'bert/encoder/layer_._9/attention/self/query/bias:0', 'bert/encoder/layer_._11/attention/self/value/kernel:0', 'bert/encoder/layer_._7/attention/self/key/bias:0', 'bert/encoder/layer_._1/intermediate/dense/bias:0', 'bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'bert/encoder/layer_._3/attention/self/value/bias:0', 'bert/pooler/dense/bias:0']\n- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier', '']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Logits: tf.Tensor(\n[[ 0.2523496  -0.04804751]\n [ 0.17488196 -0.05096127]], shape=(2, 2), dtype=float32)\nProbabilities: tf.Tensor(\n[[0.5745396  0.42546043]\n [0.556222   0.44377795]], shape=(2, 2), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 🌟 Part 8 : Advanced Sequence Models 🌟","metadata":{}},{"cell_type":"markdown","source":"### 🔄 Bidirectional RNNs (BiRNN)","metadata":{}},{"cell_type":"markdown","source":"Bidirectional RNNs process data in both forward and backward directions, capturing context from both past and future inputs.","metadata":{}},{"cell_type":"markdown","source":"##### What are BiRNNs?\n* Bidirectional Context: Captures dependencies from both directions.\n* Applications: Suitable for tasks requiring context from both past and future inputs.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Bidirectional, LSTM, Dense\n\n# BiRNN model\nmodel = tf.keras.Sequential([\n    Bidirectional(LSTM(64, return_sequences=True), input_shape=(10, 32)),\n    Dense(10)\n])\n\nmodel.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-03T02:25:42.966529Z","iopub.execute_input":"2024-07-03T02:25:42.967087Z","iopub.status.idle":"2024-07-03T02:25:43.087975Z","shell.execute_reply.started":"2024-07-03T02:25:42.967047Z","shell.execute_reply":"2024-07-03T02:25:43.086951Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m49,664\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m)         │         \u001b[38;5;34m1,290\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,664</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,954\u001b[0m (199.04 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,954</span> (199.04 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,954\u001b[0m (199.04 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,954</span> (199.04 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"### 🚀 Sequence-to-Sequence (Seq2Seq) Models","metadata":{}},{"cell_type":"markdown","source":"##### Seq2Seq models are used for tasks like machine translation and text summarization, mapping input sequences to output sequences.","metadata":{}},{"cell_type":"markdown","source":"What are Seq2Seq Models?\n* Encoder-Decoder Architecture: Encode input sequence into a fixed-dimensional vector and decode into output sequence.\n* Applications: Machine translation, text summarization, etc.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, LSTM, Dense\nfrom tensorflow.keras.models import Model\n\n# Seq2Seq model\nencoder_inputs = Input(shape=(None, 256))\nencoder = LSTM(512, return_state=True)\nencoder_outputs, state_h, state_c = encoder(encoder_inputs)\nencoder_states = [state_h, state_c]\n\ndecoder_inputs = Input(shape=(None, 256))\ndecoder_lstm = LSTM(512, return_sequences=True, return_state=True)\ndecoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\ndecoder_dense = Dense(128, activation='softmax')\ndecoder_outputs = decoder_dense(decoder_outputs)\n\nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs)\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-03T02:26:03.224926Z","iopub.execute_input":"2024-07-03T02:26:03.225361Z","iopub.status.idle":"2024-07-03T02:26:03.686567Z","shell.execute_reply.started":"2024-07-03T02:26:03.225329Z","shell.execute_reply":"2024-07-03T02:26:03.685403Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),     │  \u001b[38;5;34m1,574,912\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │  \u001b[38;5;34m1,574,912\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n│                     │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n│                     │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n│                     │ \u001b[38;5;34m512\u001b[0m)]             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │     \u001b[38;5;34m65,664\u001b[0m │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,215,488\u001b[0m (12.27 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,215,488</span> (12.27 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,215,488\u001b[0m (12.27 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,215,488</span> (12.27 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"### 🛠️ Transformer-based Seq2Seq Models","metadata":{}},{"cell_type":"markdown","source":"##### Transformer-based Seq2Seq models improve upon traditional Seq2Seq architectures with attention mechanisms for better long-range dependencies.","metadata":{}},{"cell_type":"markdown","source":"##### What are Transformer-based Seq2Seq Models?\n* Attention Mechanisms: Capture long-range dependencies using attention.\n* Applications: Machine translation, document summarization, etc.","metadata":{}},{"cell_type":"code","source":"from transformers import EncoderDecoderModel, BertTokenizer\n\nmodel_name = 'bert-base-uncased'\ntokenizer = BertTokenizer.from_pretrained(model_name)\nmodel = EncoderDecoderModel.from_encoder_decoder_pretrained(model_name, model_name)\n\nsource_text = [\"Translate this sentence.\", \"Summarize this paragraph.\"]\ntarget_text = [\"Traduzca esta oración.\", \"Resuma este párrafo.\"]\n\ninputs = tokenizer(source_text, return_tensors='pt', padding=True, truncation=True, max_length=128)\nlabels = tokenizer(target_text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n\noutputs = model(**inputs, decoder_input_ids=labels.input_ids)\n\nprint(\"Loss:\", outputs.loss)\nprint(\"Logits shape:\", outputs.logits.shape)\n\ngenerated_ids = outputs.logits.argmax(dim=-1)\ngenerated_text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\nprint(\"Generated Text:\")\nfor text in generated_text:\n    print(text)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-03T02:27:56.414083Z","iopub.execute_input":"2024-07-03T02:27:56.415491Z","iopub.status.idle":"2024-07-03T02:28:04.292954Z","shell.execute_reply.started":"2024-07-03T02:27:56.415432Z","shell.execute_reply":"2024-07-03T02:28:04.291448Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of the model checkpoint at bert-base-uncased were not used when initializing BertLMHeadModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertLMHeadModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.value.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Loss: None\nLogits shape: torch.Size([2, 11, 30522])\nGenerated Text:\n. as as as as as as as as as.\nthe as as as as as as as. and ;\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 🌟 Part 9 : Generative AI 🌟","metadata":{}},{"cell_type":"markdown","source":"### 🔁 Autoregressive Models","metadata":{}},{"cell_type":"markdown","source":"##### Autoregressive models generate data by predicting the next value in a sequence based on the previous values. They are great for tasks like text generation and time series forecasting.","metadata":{}},{"cell_type":"markdown","source":"##### What are Autoregressive Models?\n* Sequential Prediction: Predicts each value in a sequence based on preceding values.\n* Applications: Text generation, time series forecasting.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense\n\n# Define an autoregressive model for text generation\nclass AutoregressiveModel(tf.keras.Model):\n    def __init__(self, vocab_size, embedding_dim, hidden_units):\n        super(AutoregressiveModel, self).__init__()\n        self.embedding = Embedding(vocab_size, embedding_dim)\n        self.lstm = LSTM(hidden_units, return_sequences=True, return_state=True)\n        self.dense = Dense(vocab_size)\n    \n    def call(self, inputs, states=None, return_state=False, training=False):\n        x = self.embedding(inputs, training=training)\n        if states is None:\n            states = [tf.zeros((tf.shape(inputs)[0], self.lstm.units)), \n                      tf.zeros((tf.shape(inputs)[0], self.lstm.units))]\n        x, *states = self.lstm(x, initial_state=states, training=training)\n        x = self.dense(x, training=training)\n        \n        if return_state:\n            return x, states\n        else:\n            return x\n\nvocab_size = 10000\nembedding_dim = 256\nhidden_units = 512\n\nmodel = AutoregressiveModel(vocab_size, embedding_dim, hidden_units)\nexample_input = tf.random.uniform((1, 10), dtype=tf.int32, minval=0, maxval=vocab_size)\nmodel(example_input)\n\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-10T17:20:02.688369Z","iopub.execute_input":"2024-07-10T17:20:02.691468Z","iopub.status.idle":"2024-07-10T17:20:03.509851Z","shell.execute_reply.started":"2024-07-10T17:20:02.691414Z","shell.execute_reply":"2024-07-10T17:20:03.508909Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"autoregressive_model_3\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoregressive_model_3\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │     \u001b[38;5;34m2,560,000\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │     \u001b[38;5;34m1,574,912\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_35 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │     \u001b[38;5;34m5,130,000\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,000</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130,000</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,264,912\u001b[0m (35.34 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,264,912</span> (35.34 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,264,912\u001b[0m (35.34 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,264,912</span> (35.34 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"### 🤖 Generative Adversarial Networks","metadata":{}},{"cell_type":"markdown","source":"##### GANs consist of two neural networks, the generator and the discriminator, that compete with each other to generate realistic data.","metadata":{}},{"cell_type":"markdown","source":"What are GANs?\n* Generator: Creates fake data resembling real data.\n* Discriminator: Differentiates between real and fake data.\n* Applications: Image generation, data augmentation.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Dense, LeakyReLU, Reshape, Flatten\nfrom tensorflow.keras.models import Sequential\n\n# the generator model\ndef build_generator(latent_dim):\n    model = Sequential([\n        Dense(128, input_dim=latent_dim),\n        LeakyReLU(alpha=0.01),\n        Dense(256),\n        LeakyReLU(alpha=0.01),\n        Dense(512),\n        LeakyReLU(alpha=0.01),\n        Dense(28*28*1, activation='tanh'),\n        Reshape((28, 28, 1))\n    ])\n    return model\n\n# the discriminator model\ndef build_discriminator(img_shape):\n    model = Sequential([\n        Flatten(input_shape=img_shape),\n        Dense(512),\n        LeakyReLU(alpha=0.01),\n        Dense(256),\n        LeakyReLU(alpha=0.01),\n        Dense(1, activation='sigmoid')\n    ])\n    return model\n\nlatent_dim = 100\nimg_shape = (28, 28, 1)\n\ngenerator = build_generator(latent_dim)\ndiscriminator = build_discriminator(img_shape)\ndiscriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\ngenerator.summary()\ndiscriminator.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-10T19:55:57.457158Z","iopub.execute_input":"2024-07-10T19:55:57.457567Z","iopub.status.idle":"2024-07-10T19:56:13.855071Z","shell.execute_reply.started":"2024-07-10T19:55:57.457529Z","shell.execute_reply":"2024-07-10T19:56:13.853911Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-07-10 19:55:59.804632: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-10 19:55:59.804818: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-10 19:55:59.975831: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m12,928\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m33,024\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │       \u001b[38;5;34m402,192\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,928</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">402,192</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m579,728\u001b[0m (2.21 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">579,728</span> (2.21 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m579,728\u001b[0m (2.21 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">579,728</span> (2.21 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m401,920\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_4 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">401,920</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m533,505\u001b[0m (2.04 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">533,505</span> (2.04 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m533,505\u001b[0m (2.04 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">533,505</span> (2.04 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"### 🌌 Variational Autoencoders","metadata":{}},{"cell_type":"markdown","source":"##### VAEs are a type of autoencoder that generates new data by learning a probabilistic latent space representation.","metadata":{}},{"cell_type":"markdown","source":"##### Example application\n* Image Generation: Produce new images that capture the style of your training data.\n* Anomaly Detection: Identify unusual data points in datasets.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Dense, Lambda, Layer\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.losses import binary_crossentropy\nfrom tensorflow.keras import backend as K\n\nclass Sampling(Layer):\n    def call(self, inputs):\n        z_mean, z_log_var = inputs\n        batch = tf.shape(z_mean)[0]\n        dim = tf.shape(z_mean)[1]\n        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n\ninput_dim = 784\nlatent_dim = 2\n\ninputs = Input(shape=(input_dim,))\nh = Dense(256, activation='relu')(inputs)\nz_mean = Dense(latent_dim)(h)\nz_log_var = Dense(latent_dim)(h)\nz = Sampling()([z_mean, z_log_var])\n\nencoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\nencoder.summary()\n\nlatent_inputs = Input(shape=(latent_dim,))\nh = Dense(256, activation='relu')(latent_inputs)\noutputs = Dense(input_dim, activation='sigmoid')(h)\n\ndecoder = Model(latent_inputs, outputs, name='decoder')\ndecoder.summary()","metadata":{"execution":{"iopub.status.busy":"2024-07-10T17:17:27.689876Z","iopub.execute_input":"2024-07-10T17:17:27.690281Z","iopub.status.idle":"2024-07-10T17:17:27.797162Z","shell.execute_reply.started":"2024-07-10T17:17:27.690248Z","shell.execute_reply":"2024-07-10T17:17:27.795947Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"encoder\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_10      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_29 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m200,960\u001b[0m │ input_layer_10[\u001b[38;5;34m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_30 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │        \u001b[38;5;34m514\u001b[0m │ dense_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_31 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │        \u001b[38;5;34m514\u001b[0m │ dense_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ sampling_3          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ dense_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│ (\u001b[38;5;33mSampling\u001b[0m)          │                   │            │ dense_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_10      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">200,960</span> │ input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> │ dense_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> │ dense_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ sampling_3          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sampling</span>)          │                   │            │ dense_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m201,988\u001b[0m (789.02 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">201,988</span> (789.02 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m201,988\u001b[0m (789.02 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">201,988</span> (789.02 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"decoder\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"decoder\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_11 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_32 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │           \u001b[38;5;34m768\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_33 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │       \u001b[38;5;34m201,488\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">201,488</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m202,256\u001b[0m (790.06 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">202,256</span> (790.06 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m202,256\u001b[0m (790.06 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">202,256</span> (790.06 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"#VAE model\nclass VAE(Model):\n    def __init__(self, encoder, decoder, **kwargs):\n        super(VAE, self).__init__(**kwargs)\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def call(self, inputs):\n        z_mean, z_log_var, z = self.encoder(inputs)\n        reconstructed = self.decoder(z)\n        xent_loss = binary_crossentropy(inputs, reconstructed) * input_dim\n        kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n        self.add_loss(K.mean(xent_loss + kl_loss))\n        return reconstructed\n\nvae = VAE(encoder, decoder)\nvae.compile(optimizer='adam')\nvae.summary()","metadata":{"execution":{"iopub.status.busy":"2024-07-10T17:17:43.579577Z","iopub.execute_input":"2024-07-10T17:17:43.579963Z","iopub.status.idle":"2024-07-10T17:17:43.611098Z","shell.execute_reply.started":"2024-07-10T17:17:43.579933Z","shell.execute_reply":"2024-07-10T17:17:43.610088Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"vae\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"vae\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ encoder (\u001b[38;5;33mFunctional\u001b[0m)            │ ?                      │       \u001b[38;5;34m201,988\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ decoder (\u001b[38;5;33mFunctional\u001b[0m)            │ ?                      │       \u001b[38;5;34m202,256\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">201,988</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">202,256</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m404,244\u001b[0m (1.54 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">404,244</span> (1.54 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m404,244\u001b[0m (1.54 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">404,244</span> (1.54 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]}]}